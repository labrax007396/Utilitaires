{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librairies nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import commentjson\n",
    "import os\n",
    "#os.chdir('/mnt/batch/tasks/shared/LS_root/mounts/clusters/pythonnb/code/Users/david.mouquet/modeling')\n",
    "\n",
    "\n",
    "import missingno as msno\n",
    "import sys\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from onnx.onnx_pb import StringStringEntryProto\n",
    "\n",
    "# Librairies personnelles\n",
    "path = os.getcwd()\n",
    "path_src = os.path.abspath(os.path.join(path, os.pardir,\"src\"))\n",
    "sys.path.append(path_src)\n",
    "path_mode = os.path.abspath(os.path.join(path, os.pardir,\"src\",\"modelisation\"))\n",
    "sys.path.append(path_mode)\n",
    "\n",
    "from casestudy import set_exp_study\n",
    "importlib.reload(set_exp_study)\n",
    "\n",
    "import importlib\n",
    "from importdata import import_from_influxdb\n",
    "importlib.reload(import_from_influxdb)\n",
    "from analysdesc import analyse_descriptive\n",
    "from utilitaires import utilitaires\n",
    "\n",
    "import keras_tuner as kt\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, concatenate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions annexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "\n",
    "\n",
    "def plot_model_mesure(mesure,model):\n",
    "\n",
    "  import plotly.graph_objects as go\n",
    "\n",
    "  # Create traces\n",
    "  fig = go.Figure()\n",
    "\n",
    "\n",
    "  fig.add_trace(go.Scatter(x=mesure.index, y=mesure,\n",
    "                          mode='lines',\n",
    "                          name=\"Mesure\"))\n",
    "  fig.add_trace(go.Scatter(x=model.index, y=model,\n",
    "                          mode='lines',\n",
    "                          name=\"Model\"))\n",
    "\n",
    "  fig.update_layout(title='Comparaison Modele/Mesure',\n",
    "                    width=800, \n",
    "                    height=600,\n",
    "                    xaxis_title='Date',\n",
    "                    yaxis_title='IPE')                        \n",
    "\n",
    "  fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(set_exp_study)\n",
    "with open(\"experiment_config.json\", encoding='utf-8') as file:\n",
    "    exp_config = commentjson.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model_param = exp_config['dir_models']+'CONFIGS/'+exp_config['client']+'/'+exp_config['site']+'/'+exp_config['depart']+'/'+exp_config['case_study']+'/model_config.json'\n",
    "with open(file_model_param, encoding='utf-8') as file:\n",
    "    dico_model = commentjson.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq                = dico_model['freq']\n",
    "uv_mangling         = dico_model['mangling']\n",
    "nom_data_store      = dico_model['data_store']\n",
    "\n",
    "#onnx_rep = \"C:/Users/33623/Dropbox (Ultiwatt)/D - ULTIVISION INDUSTRIES/4-ARCELORMITTAL/2- DEPLOIEMENT AMF/2-Projet LOT 2/10-Models/onnx\"\n",
    "#onnx_model_name     = onnx_rep + \"/\" + site + \"/\" + uv_mangling+\".\"+model_id+\".onnx\"\n",
    "\n",
    "\n",
    "ref_periode_debut = datetime.datetime.strptime(dico_model['ref_periode_debut'], '%d/%m/%Y %H:%M:%S').isoformat()\n",
    "ref_periode_fin   = datetime.datetime.strptime(dico_model['ref_periode_fin'], '%d/%m/%Y %H:%M:%S').isoformat()\n",
    "\n",
    "\n",
    "data, clean_report, message_error = import_from_influxdb.Charger_Preparer_Data(ref_periode_debut = ref_periode_debut, \n",
    "                                         ref_periode_fin   = ref_periode_fin,\n",
    "                                         ipe_tag           = dico_model[\"tag_modelise\"],\n",
    "                                         dico_du_model     = dico_model,\n",
    "                                         use_seuil_min     = True,\n",
    "                                         use_seuil_max     = True,\n",
    "                                         clean_data        = False,\n",
    "                                         concat_after      = True,\n",
    "                                         load_unused_feature = True,\n",
    "                                         zscore            = 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recherche valeurs manquantes dans les colonnes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pourcentage de valeur manquante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_missing(x):\n",
    "    perc_missing = round(100*sum(x.isnull())/len(x),1)\n",
    "    return perc_missing\n",
    "\n",
    "print(\"Valeurs manquantes par colonne:\")\n",
    "df_missing = data.apply(num_missing, axis=0)\n",
    "print(df_missing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppression des features non utilisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_kept = [f['nom'] for tag, f in dico_model['facteurs'].items() if f['used']]\n",
    "\n",
    "data = data[[dico_model['tag_name']] + features_kept]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Découpage des données en train et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "\n",
    "train_dataset = data.sample(frac=0.8, random_state=0)\n",
    "test_dataset = data.drop(train_dataset.index)\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop(dico_model[\"tag_name\"])\n",
    "test_labels = test_features.pop(dico_model[\"tag_name\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation des facteurs numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "\n",
    "for name, column in train_features.items():\n",
    "  dtype = column.dtype\n",
    "  if dtype == object:\n",
    "    dtype = tf.string\n",
    "  else:\n",
    "    dtype = tf.float32    \n",
    "\n",
    "  inputs.append(tf.keras.Input(shape=(1,), name=name, dtype=dtype))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_inputs = {input.name:input for input in inputs\n",
    "                  if input.dtype==tf.float32}\n",
    "\n",
    "\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = layers.Normalization()\n",
    "norm.adapt(np.array(train_features[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "\n",
    "preprocessed_inputs = [all_numeric_inputs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input in inputs:\n",
    "  if input.dtype == tf.float32:\n",
    "    continue\n",
    "\n",
    "  lookup = layers.StringLookup(vocabulary=np.unique(train_features[input.name]))\n",
    "  one_hot = layers.CategoryEncoding(max_tokens=lookup.vocab_size())\n",
    "\n",
    "  x = lookup(input)\n",
    "  x = one_hot(x)\n",
    "  preprocessed_inputs.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "first_layer = layers.Dense(64, activation='relu')(preprocessed_inputs_cat)\n",
    "terminal_layer = layers.Dense(1,name='target')(first_layer)\n",
    "main_model = tf.keras.models.Model(inputs = inputs,outputs=terminal_layer,name = 'model')\n",
    "main_model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = {name: np.array(value) \n",
    "                         for name, value in train_features.items()}\n",
    "features_dict_test = {name: np.array(value) \n",
    "                         for name, value in test_features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = main_model.fit(x=features_dict, y=train_labels, epochs=600,validation_data=(features_dict_test,test_labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_train_predictions = main_model.predict(features_dict).flatten()\n",
    "df_test_predictions = main_model.predict(features_dict_test).flatten() \n",
    "df_train_predictions = pd.Series(index=train_features.index,data=df_train_predictions)\n",
    "df_test_predictions  = pd.Series(index=test_features.index,data=df_test_predictions)\n",
    "\n",
    "df_pred = pd.concat([df_train_predictions,df_test_predictions])\n",
    "df_mesure = pd.concat([train_labels,test_labels])\n",
    "df_pred.sort_index(inplace=True)\n",
    "df_mesure.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "print(r2_score(train_labels.values,df_train_predictions),r2_score(test_labels.values,df_test_predictions))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réglage Hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "\n",
    "\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=64, step=10)\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  hp_activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "\n",
    "  preprocessed_inputs_cat = layers.Concatenate(name=\"concate_input\")(preprocessed_inputs)\n",
    "  couche_1 = layers.Dense(units=hp_units, activation=hp_activation,name=\"first_layer\")(preprocessed_inputs_cat)\n",
    "  sortie = layers.Dense(1,name='target')(couche_1)\n",
    "  main_model = tf.keras.models.Model(inputs = inputs,outputs=sortie)\n",
    "  main_model.compile(loss=\"mean_squared_error\", metrics=[\"mean_squared_error\"],\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate))\n",
    "\n",
    "\n",
    "  return main_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective=\"val_mean_squared_error\",\n",
    "                     max_epochs=400,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "tuner.search(x=features_dict, y=train_labels, epochs=400,validation_data=(features_dict_test,test_labels), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models()[0]\n",
    "\n",
    "df_train_predictions = best_model.predict(features_dict).flatten()\n",
    "df_test_predictions = best_model.predict(features_dict_test).flatten() \n",
    "df_train_predictions = pd.Series(index=train_features.index,data=df_train_predictions)\n",
    "df_test_predictions  = pd.Series(index=test_features.index,data=df_test_predictions)\n",
    "\n",
    "df_pred = pd.concat([df_train_predictions,df_test_predictions])\n",
    "df_mesure = pd.concat([train_labels,test_labels])\n",
    "df_pred.sort_index(inplace=True)\n",
    "df_mesure.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "print(r2_score(train_labels.values,df_train_predictions),r2_score(test_labels.values,df_test_predictions))\n",
    "\n",
    "\n",
    "plot_model_mesure(df_mesure,df_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export vers ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(modelreport)\n",
    "\n",
    "model_type = \"réseau de neuronnes\"\n",
    "\n",
    "modelreport_json = modelreport.BuildModelReport(model_type  = model_type,\n",
    "                                                ref_periode_debut  = datetime.datetime.strftime(data.index[0], '%Y-%m-%d %H:%M:%S')  ,\n",
    "                                                ref_periode_fin= datetime.datetime.strftime(data.index[-1], '%Y-%m-%d %H:%M:%S'),\n",
    "                                                clean_report = clean_report,\n",
    "                                                description = '',\n",
    "                                                test_data_set = test_dataset,\n",
    "                                                train_data_set = train_dataset,\n",
    "                                                fitted_model = best_model,\n",
    "                                                df_num_corr = df_num_corr,\n",
    "                                                dico_model = dico_model,\n",
    "                                                data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2onnx\n",
    "(model_onnx, storage) = tf2onnx.convert.from_keras(best_model)\n",
    "model_onnx.metadata_props.append(StringStringEntryProto(key=\"ReportModel\", value = modelreport_json))\n",
    "\n",
    "with open(onnx_model_name, \"wb\") as f:\n",
    "    f.write(model_onnx.SerializeToString()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelreport_json\n",
    "\n",
    "import json\n",
    "json_rep = json.loads(modelreport_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'formula': '[model]  .Arg(\"Humidite_PAC\", [tag_33643], 7.467802861111114, 12.0081104109589) .Arg(\"Perc_Matiere_volatile_PAC\", [tag_33644], 22.106071805555555, 24.78209244755245) .Arg(\"Cokerie_Production_de_Coke\", [tag_33562], 1823.76, 4344.84) .Arg(\"Taux_Cendre\", [tag_34371], 7.4, 11.1) .Arg(\"Temps_Cuisson\", [tag_37912], 19.239522988505744, 38.66184444444445) .Outputs(\"variable_out1\")'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_rep['uv_formula']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
