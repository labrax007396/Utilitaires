{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librairies nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import commentjson\n",
    "import os\n",
    "#os.chdir('/mnt/batch/tasks/shared/LS_root/mounts/clusters/pythonnb/code/Users/david.mouquet/modeling')\n",
    "\n",
    "\n",
    "import missingno as msno\n",
    "import sys\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from onnx.onnx_pb import StringStringEntryProto\n",
    "\n",
    "sys.path.append(\"../SRC/\")\n",
    "import Utilitaires as utils\n",
    "importlib.reload(utils)\n",
    "import RapportModelisation as modelreport\n",
    "import importFromUV as preprocdata\n",
    "importlib.reload(preprocdata)\n",
    "import keras_tuner as kt\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, concatenate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions annexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "\n",
    "\n",
    "def plot_model_mesure(mesure,model):\n",
    "\n",
    "  import plotly.graph_objects as go\n",
    "\n",
    "  # Create traces\n",
    "  fig = go.Figure()\n",
    "\n",
    "\n",
    "  fig.add_trace(go.Scatter(x=mesure.index, y=mesure,\n",
    "                          mode='lines',\n",
    "                          name=\"Mesure\"))\n",
    "  fig.add_trace(go.Scatter(x=model.index, y=model,\n",
    "                          mode='lines',\n",
    "                          name=\"Model\"))\n",
    "\n",
    "  fig.update_layout(title='Comparaison Modele/Mesure',\n",
    "                    width=800, \n",
    "                    height=600,\n",
    "                    xaxis_title='Date',\n",
    "                    yaxis_title='IPE')                        \n",
    "\n",
    "  fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model_param   = \"models_param/DK-Cokerie.json\"\n",
    "\n",
    "model_id           = \"B6_Conso_Energ_Gaz_Hour\"\n",
    "site               = \"DK-Cokerie\"\n",
    "\n",
    "###############################################################\n",
    "\n",
    "with open(file_model_param, encoding='utf-8') as file:\n",
    "    dico_model_all = commentjson.load(file)\n",
    "\n",
    "dico_model = dico_model_all[model_id]\n",
    "\n",
    "\n",
    "\n",
    "#pkl_model_name      = \"resu/models/\"+model_id+\"_\"+ dico_model['type_model'] + \"_\" +dico_model['freq']+\".pkl\"\n",
    "\n",
    "nom_model_registre  = dico_model['nom_model_registre']\n",
    "freq                = dico_model['freq']\n",
    "uv_mangling         = dico_model['mangling']\n",
    "nom_data_store      = dico_model['data_store']\n",
    "\n",
    "onnx_rep = \"C:/Users/33623/Dropbox (Ultiwatt)/D - ULTIVISION INDUSTRIES/4-ARCELORMITTAL/2- DEPLOIEMENT AMF/2-Projet LOT 2/10-Models/onnx\"\n",
    "onnx_model_name     = onnx_rep + \"/\" + site + \"/\" + uv_mangling+\".\"+model_id+\".onnx\"\n",
    "\n",
    "\n",
    "ref_periode_debut = datetime.datetime.strptime(dico_model['ref_periode_debut'], '%d/%m/%Y %H:%M:%S').isoformat()\n",
    "ref_periode_fin   = datetime.datetime.strptime(dico_model['ref_periode_fin'], '%d/%m/%Y %H:%M:%S').isoformat()\n",
    "\n",
    "\n",
    "data, clean_report = preprocdata.Charger_Preparer_Data(ref_periode_debut = ref_periode_debut, \n",
    "                                         ref_periode_fin   = ref_periode_fin,\n",
    "                                         ipe_tag           = dico_model[\"tag_modelise\"],\n",
    "                                         dico_du_model     = dico_model,\n",
    "                                         use_seuil_min     = True,\n",
    "                                         use_seuil_max     = True,\n",
    "                                         clean_data        = False,\n",
    "                                         concat_after      = True,\n",
    "                                         load_unused_feature = True,\n",
    "                                         zscore            = 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppression périodes avec données abberantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "periode_ab = [\"2019-06-01 06:00:00\",\"2019-06-30 06:00:00\"]\n",
    "index_list= data[(data.index >= periode_ab[0]) & (data.index <= periode_ab[1])].index.tolist()\n",
    "data.drop(index_list , inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recherche valeurs manquantes dans les colonnes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pourcentage de valeur manquante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_missing(x):\n",
    "    perc_missing = round(100*sum(x.isnull())/len(x),1)\n",
    "    return perc_missing\n",
    "\n",
    "print(\"Valeurs manquantes par colonne:\")\n",
    "df_missing = data.apply(num_missing, axis=0)\n",
    "print(df_missing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "list_unit = [dico_model['tag_unit']] + [f['unit'] for f in dico_model['facteurs'].values() if f['used']]\n",
    "list_unit = [dico_model['tag_unit']] + [f['unit'] for f in dico_model['facteurs'].values()]\n",
    "\n",
    "\n",
    "var_numerique = [v for v in data.columns if data[v].dtypes != 'object']\n",
    "\n",
    "var_numerique_unit = [v+' '+u for v,u in zip(var_numerique, list_unit)]\n",
    "\n",
    "data_num = data[var_numerique]\n",
    "\n",
    "n_var_num = len(var_numerique)\n",
    "var_numerique\n",
    "if n_var_num%2 == 0:\n",
    "    nrows = int(n_var_num/2)\n",
    "else:\n",
    "    nrows = int((n_var_num+1)/2)\n",
    "\n",
    "fig = make_subplots(rows=nrows, cols=2,subplot_titles=tuple(var_numerique_unit))\n",
    "\n",
    "if n_var_num%2 == 0:\n",
    "    for row in range(nrows):\n",
    "        fig.add_trace(go.Histogram(x=data_num[var_numerique[2*row]]),row=row+1, col=1)\n",
    "        fig.add_trace(go.Histogram(x=data_num[var_numerique[2*row+1]]),row=row+1, col=2)\n",
    "else:\n",
    "    for row in range(nrows-1):\n",
    "        fig.add_trace(go.Histogram(x=data_num[var_numerique[2*row]]),row=row+1, col=1)\n",
    "        fig.add_trace(go.Histogram(x=data_num[var_numerique[2*row+1]]),row=row+1, col=2)\n",
    "\n",
    "    fig.add_trace(go.Histogram(x=data_num[var_numerique[2*nrows-2]]),row=nrows, col=1)\n",
    "    \n",
    "\n",
    "fig.update_annotations(font_size=12)\n",
    "fig.update_layout(\n",
    "    title_text=\"Histogramme des variables numériques\",\n",
    "    autosize=False,\n",
    "    width=1000,\n",
    "    height=nrows*300)\n",
    "\n",
    "#for i, unit in enumerate(list_unit): \n",
    "#    fig['layout']['xaxis{}'.format(i+1)]['title']=unit\n",
    "\n",
    "\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "list_unit = [dico_model['tag_unit']] + [f['unit'] for f in dico_model['facteurs'].values() if f['used']]\n",
    "\n",
    "var_numerique = [v for v in data.columns if data[v].dtypes != 'object']\n",
    "data_num = data[var_numerique]\n",
    "\n",
    "n_var_num = len(var_numerique)\n",
    "var_numerique\n",
    "if n_var_num%2 == 0:\n",
    "    nrows = int(n_var_num/2)\n",
    "else:\n",
    "    nrows = int((n_var_num+1)/2)\n",
    "\n",
    "fig = make_subplots(rows=nrows, cols=2,subplot_titles=tuple(var_numerique))\n",
    "\n",
    "if n_var_num%2 == 0:\n",
    "    for row in range(nrows):\n",
    "\n",
    "        b_plot_1 = go.Box(\n",
    "            y=data_num[var_numerique[2*row]],\n",
    "            boxpoints='outliers'\n",
    "        )\n",
    "        b_plot_2 = go.Box(\n",
    "            y=data_num[var_numerique[2*row+1]],\n",
    "            boxpoints='outliers'\n",
    "        )\n",
    "\n",
    "        fig.add_trace(b_plot_1,row=row+1, col=1)\n",
    "        fig.add_trace(b_plot_2,row=row+1, col=2)\n",
    "else:\n",
    "    for row in range(nrows-1):\n",
    "\n",
    "        b_plot_1 = go.Box(\n",
    "            y=data_num[var_numerique[2*row]],\n",
    "            boxpoints='outliers' # only outliers\n",
    "\n",
    "        )\n",
    "        b_plot_2 = go.Box(\n",
    "            y=data_num[var_numerique[2*row+1]],\n",
    "            boxpoints='outliers'\n",
    "        )\n",
    "\n",
    "        fig.add_trace(b_plot_1,row=row+1, col=1)\n",
    "        fig.add_trace(b_plot_2,row=row+1, col=2)\n",
    "\n",
    "    b_plot_3 = go.Box(\n",
    "                y=data_num[var_numerique[2*nrows-2]],\n",
    "                boxpoints='outliers'\n",
    "    )\n",
    "\n",
    "    fig.add_trace(b_plot_3,row=nrows, col=1)\n",
    "    \n",
    "\n",
    "fig.update_annotations(font_size=12)\n",
    "fig.update_layout(\n",
    "    title_text=\"Box plot des variables numériques\",\n",
    "    autosize=False,\n",
    "    width=1000,\n",
    "    height=nrows*300)\n",
    "\n",
    "\n",
    "#for i, unit in enumerate(list_unit): \n",
    "#    fig['layout']['yaxis{}'.format(i+1)]['title']=unit\n",
    "#    fig['layout']['xaxis{}'.format(i+1)]['title']=''\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coefficient de corrélation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_corr = utils.Compute_Corr_Coef(data=data, dico_model =dico_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppression des features non utilisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_model_param, encoding='utf-8') as file:\n",
    "    dico_model_all = commentjson.load(file)\n",
    "\n",
    "dico_model = dico_model_all[model_id]\n",
    "features_kept = [f['nom'] for tag, f in dico_model['facteurs'].items() if f['used']]\n",
    "\n",
    "data = data[[dico_model['tag_name']] + features_kept]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Découpage des données en train et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "\n",
    "train_dataset = data.sample(frac=0.8, random_state=0)\n",
    "test_dataset = data.drop(train_dataset.index)\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop(dico_model[\"tag_name\"])\n",
    "test_labels = test_features.pop(dico_model[\"tag_name\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation des facteurs numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "\n",
    "for name, column in train_features.items():\n",
    "  dtype = column.dtype\n",
    "  if dtype == object:\n",
    "    dtype = tf.string\n",
    "  else:\n",
    "    dtype = tf.float32    \n",
    "\n",
    "  inputs.append(tf.keras.Input(shape=(1,), name=name, dtype=dtype))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_inputs = {input.name:input for input in inputs\n",
    "                  if input.dtype==tf.float32}\n",
    "\n",
    "\n",
    "x = layers.Concatenate()(list(numeric_inputs.values()))\n",
    "norm = layers.Normalization()\n",
    "norm.adapt(np.array(train_features[numeric_inputs.keys()]))\n",
    "all_numeric_inputs = norm(x)\n",
    "\n",
    "preprocessed_inputs = [all_numeric_inputs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input in inputs:\n",
    "  if input.dtype == tf.float32:\n",
    "    continue\n",
    "\n",
    "  lookup = layers.StringLookup(vocabulary=np.unique(train_features[input.name]))\n",
    "  one_hot = layers.CategoryEncoding(max_tokens=lookup.vocab_size())\n",
    "\n",
    "  x = lookup(input)\n",
    "  x = one_hot(x)\n",
    "  preprocessed_inputs.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 8) dtype=float32 (created by layer 'normalization')>,\n",
       " <KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'category_encoding')>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_inputs_cat = layers.Concatenate()(preprocessed_inputs)\n",
    "first_layer = layers.Dense(64, activation='relu')(preprocessed_inputs_cat)\n",
    "terminal_layer = layers.Dense(1,name='target')(first_layer)\n",
    "main_model = tf.keras.models.Model(inputs = inputs,outputs=terminal_layer,name = 'model')\n",
    "main_model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = {name: np.array(value) \n",
    "                         for name, value in train_features.items()}\n",
    "features_dict_test = {name: np.array(value) \n",
    "                         for name, value in test_features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = main_model.fit(x=features_dict, y=train_labels, epochs=600,validation_data=(features_dict_test,test_labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_train_predictions = main_model.predict(features_dict).flatten()\n",
    "df_test_predictions = main_model.predict(features_dict_test).flatten() \n",
    "df_train_predictions = pd.Series(index=train_features.index,data=df_train_predictions)\n",
    "df_test_predictions  = pd.Series(index=test_features.index,data=df_test_predictions)\n",
    "\n",
    "df_pred = pd.concat([df_train_predictions,df_test_predictions])\n",
    "df_mesure = pd.concat([train_labels,test_labels])\n",
    "df_pred.sort_index(inplace=True)\n",
    "df_mesure.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "print(r2_score(train_labels.values,df_train_predictions),r2_score(test_labels.values,df_test_predictions))\n",
    "\n",
    "\n",
    "plot_model_mesure(df_mesure,df_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réglage Hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "\n",
    "\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=64, step=10)\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  hp_activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "\n",
    "  preprocessed_inputs_cat = layers.Concatenate(name=\"concate_input\")(preprocessed_inputs)\n",
    "  couche_1 = layers.Dense(units=hp_units, activation=hp_activation,name=\"first_layer\")(preprocessed_inputs_cat)\n",
    "  sortie = layers.Dense(1,name='target')(couche_1)\n",
    "  main_model = tf.keras.models.Model(inputs = inputs,outputs=sortie)\n",
    "  main_model.compile(loss=\"mean_squared_error\", metrics=[\"mean_squared_error\"],\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate))\n",
    "\n",
    "\n",
    "  return main_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    " \n",
    "shutil.rmtree('my_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective=\"val_mean_squared_error\",\n",
    "                     max_epochs=400,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "tuner.search(x=features_dict, y=train_labels, epochs=400,validation_data=(features_dict_test,test_labels), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models()[0]\n",
    "\n",
    "df_train_predictions = best_model.predict(features_dict).flatten()\n",
    "df_test_predictions = best_model.predict(features_dict_test).flatten() \n",
    "df_train_predictions = pd.Series(index=train_features.index,data=df_train_predictions)\n",
    "df_test_predictions  = pd.Series(index=test_features.index,data=df_test_predictions)\n",
    "\n",
    "df_pred = pd.concat([df_train_predictions,df_test_predictions])\n",
    "df_mesure = pd.concat([train_labels,test_labels])\n",
    "df_pred.sort_index(inplace=True)\n",
    "df_mesure.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "print(r2_score(train_labels.values,df_train_predictions),r2_score(test_labels.values,df_test_predictions))\n",
    "\n",
    "\n",
    "plot_model_mesure(df_mesure,df_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export vers ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Humidite_PAC': -0.0447015855944182,\n",
       " 'Perc_Matiere_volatile_PAC': -0.1135628220447223,\n",
       " 'Cokerie_Production_de_Coke': 0.8907968874530585,\n",
       " 'Taux_Cendre': 0.14641037781061178,\n",
       " 'Temps_Cuisson': -0.8386313651090204}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(modelreport)\n",
    "\n",
    "model_type = \"réseau de neuronnes\"\n",
    "\n",
    "modelreport_json = modelreport.BuildModelReport(model_type  = model_type,\n",
    "                                                ref_periode_debut  = datetime.datetime.strftime(data.index[0], '%Y-%m-%d %H:%M:%S')  ,\n",
    "                                                ref_periode_fin= datetime.datetime.strftime(data.index[-1], '%Y-%m-%d %H:%M:%S'),\n",
    "                                                clean_report = clean_report,\n",
    "                                                description = '',\n",
    "                                                test_data_set = test_dataset,\n",
    "                                                train_data_set = train_dataset,\n",
    "                                                fitted_model = best_model,\n",
    "                                                df_num_corr = df_num_corr,\n",
    "                                                dico_model = dico_model,\n",
    "                                                data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2onnx\n",
    "(model_onnx, storage) = tf2onnx.convert.from_keras(best_model)\n",
    "model_onnx.metadata_props.append(StringStringEntryProto(key=\"ReportModel\", value = modelreport_json))\n",
    "\n",
    "with open(onnx_model_name, \"wb\") as f:\n",
    "    f.write(model_onnx.SerializeToString()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/33623/Dropbox (Ultiwatt)/D - ULTIVISION INDUSTRIES/4-ARCELORMITTAL/2- DEPLOIEMENT AMF/2-Projet LOT 2/10-Models/onnx/DK-Cokerie/Tech.DK.CK.CK_B6_B7.Cokerie_Conso_Energ_Gaz_Inv.onnx'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelreport_json\n",
    "\n",
    "import json\n",
    "json_rep = json.loads(modelreport_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'formula': '[model]  .Arg(\"Humidite_PAC\", [tag_33643], 7.467802861111114, 12.0081104109589) .Arg(\"Perc_Matiere_volatile_PAC\", [tag_33644], 22.106071805555555, 24.78209244755245) .Arg(\"Cokerie_Production_de_Coke\", [tag_33562], 1823.76, 4344.84) .Arg(\"Taux_Cendre\", [tag_34371], 7.4, 11.1) .Arg(\"Temps_Cuisson\", [tag_37912], 19.239522988505744, 38.66184444444445) .Outputs(\"variable_out1\")'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_rep['uv_formula']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
