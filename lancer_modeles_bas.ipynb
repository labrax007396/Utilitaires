{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Production Modeles"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Import des librairies nécessaires"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1650876388259
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Librairie générales\n",
        "\n",
        "import commentjson\n",
        "import os\n",
        "import sys\n",
        "import importlib\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# Librairies personnelles\n",
        "path = os.getcwd()\n",
        "path_src = os.path.abspath(os.path.join(path, os.pardir,\"src\"))\n",
        "sys.path.append(path_src)\n",
        "path_mode = os.path.abspath(os.path.join(path, os.pardir,\"src\",\"modelisation\"))\n",
        "sys.path.append(path_mode)\n",
        "\n",
        "from casestudy import set_exp_study\n",
        "importlib.reload(set_exp_study)\n",
        "\n",
        "from importdata import import_from_influxdb\n",
        "importlib.reload(import_from_influxdb)\n",
        "from analysdesc import analyse_descriptive\n",
        "from utilitaires import utilitaires\n",
        "from modelisation import mlflow_functions\n",
        "from modelisation import lgbm_functions\n",
        "from modelisation import build_run_models\n",
        "importlib.reload(analyse_descriptive)\n",
        "\n",
        "\n",
        "#from modelisation import build_run_models, lgbm_functions, mlflow_functions\n",
        "\n",
        "# Librairies ML\n",
        "import mlflow\n",
        "from mlflow.tracking import MlflowClient\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "import optuna\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Set up de l'expérience"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "client = \"Demo\"\n",
        "\n",
        "importlib.reload(set_exp_study)\n",
        "with open(\"configs/\"+client+\"/experiment_config.json\", encoding='utf-8') as file:\n",
        "    exp_config = commentjson.load(file)\n",
        "\n",
        "dico_exp = set_exp_study.Experiment_Params(exp_config, mlflow)\n",
        "\n",
        "dico_figure = dict() # Dictionnaire où sont stockées les figures"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Import des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1650876412840
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "data, clean_report, message_error = import_from_influxdb.Charger_Preparer_Data(ref_periode_debut = dico_exp['ref_periode_debut'], \n",
        "                                         ref_periode_fin   = dico_exp['ref_periode_fin'],\n",
        "                                         ipe_tag           = dico_exp['dico_model']['tag_modelise'],\n",
        "                                         dico_du_model     = dico_exp['dico_model'],\n",
        "                                         use_seuil_min     = False,\n",
        "                                         use_seuil_max     = False,\n",
        "                                         clean_data        = False,                            \n",
        "                                         concat_after      = True,\n",
        "                                         load_unused_feature = True,\n",
        "                                         client            = exp_config['client'],\n",
        "                                         zscore            = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "debut_ref =  \"2024-02-05 18:08:00\"\n",
        "fin_ref   =  \"2024-03-11 05:00:00\"\n",
        "\n",
        "debut_suivi = \"2023-09-02 13:31:00\"\n",
        "fin_suivi   = \"2024-01-31 16:17:00\"\n",
        "\n",
        "data_ref = data[(data.index>=debut_ref) & (data.index<=fin_ref)]\n",
        "data_suivi = data[(data.index>=debut_suivi) & (data.index<=fin_suivi)]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modélisation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Lancement optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lightgbm import LGBMRegressor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import lightgbm\n",
        "\n",
        "data_ref.dropna(inplace=True)\n",
        "Y_ref  = data_ref[data_ref.columns[0]]\n",
        "X_ref  = data_ref.drop(columns=data_ref.columns[0])\n",
        "\n",
        "\n",
        "callbacks = [lightgbm.early_stopping(100, verbose=0), lightgbm.log_evaluation(period=0)]\n",
        "\n",
        "fixed_hp =   {\n",
        "        'metric': 'rmse', \n",
        "        'random_state': 48,\n",
        "    }\n",
        "\n",
        "def objective(trial,data=X_ref,target=Y_ref):\n",
        "\n",
        "    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.2,random_state=42)\n",
        "\n",
        "    callbacks = [lightgbm.early_stopping(100, verbose=0), lightgbm.log_evaluation(period=0)]\n",
        "\n",
        "    model = LGBMRegressor()\n",
        "    \n",
        "    param = { \n",
        "         'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.5,0.6,0.7]),\n",
        "         'learning_rate': trial.suggest_categorical('learning_rate', [0.02,0.04,0.08,0.12]),\n",
        "         'max_depth': trial.suggest_categorical('max_depth', [4,5,6]),\n",
        "         'n_estimators':trial.suggest_int('n_estimators',10,500,10),\n",
        "         'num_leaves' : trial.suggest_int('num_leaves',100,200,20),\n",
        "         'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n",
        "         'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n",
        "         'subsample': trial.suggest_categorical('subsample', [0.7,0.8,0.9])\n",
        "    }\n",
        "\n",
        "\n",
        "    for p, pv in fixed_hp.items():\n",
        "        param[p] = pv\n",
        "\n",
        "    model = LGBMRegressor(**param)\n",
        "\n",
        "    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],callbacks=callbacks)\n",
        "\n",
        "    preds_train = model.predict(train_x)  \n",
        "    rmse_train = mean_squared_error(train_y, preds_train,squared=False)\n",
        "    preds_test = model.predict(test_x)\n",
        "    rmse_test = mean_squared_error(test_y, preds_test,squared=False)\n",
        "\n",
        "\n",
        "\n",
        "    alpha_overfit = 0.4\n",
        "    score_final = alpha_overfit*rmse_train + (1-alpha_overfit)*np.abs(rmse_train-rmse_test)\n",
        "      \n",
        "    return score_final\n",
        "\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=200)\n",
        "print('Number of finished trials:', len(study.trials))\n",
        "print('Best trial:', study.best_trial.params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#study.trials_dataframe()\n",
        "optuna.visualization.plot_optimization_history(study)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Relance du modèle avec les meilleurs HP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_params=study.best_params\n",
        "for p, pv in fixed_hp.items():\n",
        "    best_params[p] = pv\n",
        "\n",
        "model = LGBMRegressor(**best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(X_ref,Y_ref)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y_ref_pred = model.predict(X_ref)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "r2_score(Y_ref,Y_ref_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "lower = LGBMRegressor(**best_params,objective = 'quantile', alpha = 1 - 0.95)\n",
        "lower.fit(X_ref,Y_ref)\n",
        "lower_pred_ref = lower.predict(X_ref)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "upper = LGBMRegressor(**best_params,objective = 'quantile', alpha = 0.95)\n",
        "upper.fit(X_ref,Y_ref)\n",
        "upper_pred_ref = upper.predict(X_ref)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_ref['model'] = Y_ref_pred\n",
        "data_ref['lower_pred'] = lower_pred_ref\n",
        "data_ref['upper_pred'] = upper_pred_ref\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.dropna(inplace=True)\n",
        "Y  = data[data_ref.columns[0]]\n",
        "X  = data.drop(columns=data_ref.columns[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "upper_pred = upper.predict(X)\n",
        "lower_pred = lower.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data['lower']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_upper_lower = pd.DataFrame(index=data.index,data={'upper':upper_pred,'lower':lower_pred})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_upper_lower.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "\n",
        "# Create traces\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=data_ref.index, y=data_ref['DEB_VAP_TOTAL'],\n",
        "                    mode='lines',\n",
        "                    name='mesure'))\n",
        "fig.add_trace(go.Scatter(x=data_ref.index, y=data_ref['model'],\n",
        "                    mode='lines',\n",
        "                    name='modele'))\n",
        "fig.add_trace(go.Scatter(x=data_ref.index, y=data_ref['lower_pred'],\n",
        "                    mode='lines',\n",
        "                    name='lower_pred'))\n",
        "fig.add_trace(go.Scatter(x=data_ref.index, y=data_ref['upper_pred'],\n",
        "                    mode='lines',\n",
        "                    name='upper_pred'))                    \n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer\n",
        "import onnxruntime as rt\n",
        "from onnxmltools import convert_lightgbm\n",
        "from skl2onnx import to_onnx, update_registered_converter\n",
        "from skl2onnx.common.shape_calculator import calculate_linear_regressor_output_shapes  # noqa\n",
        "from onnxmltools import __version__ as oml_version\n",
        "from onnxmltools.convert.lightgbm.operator_converters.LightGbm import convert_lightgbm\n",
        "from onnxruntime.capi.onnxruntime_pybind11_state import Fail as OrtFail\n",
        "from skl2onnx import convert_sklearn, update_registered_converter\n",
        "from skl2onnx.common.shape_calculator import calculate_linear_classifier_output_shapes  # noqa\n",
        "from onnxmltools.convert.lightgbm.operator_converters.LightGbm import convert_lightgbm  # noqa\n",
        "import onnxmltools.convert.common.data_types\n",
        "from skl2onnx.common.data_types import FloatTensorType, StringTensorType\n",
        "from skl2onnx.common.data_types import Int64TensorType\n",
        "from onnx.onnx_pb import StringStringEntryProto\n",
        "from lightgbm import LGBMRegressor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def skl2onnx_convert_lightgbm(scope, operator, container):\n",
        "    options = scope.get_options(operator.raw_operator)\n",
        "    if 'split' in options:\n",
        "        if pv.Version(oml_version) < pv.Version('1.9.2'):\n",
        "            warnings.warn(\n",
        "                \"Option split was released in version 1.9.2 but %s is \"\n",
        "                \"installed. It will be ignored.\" % oml_version)\n",
        "        operator.split = options['split']\n",
        "    else:\n",
        "        operator.split = None\n",
        "    convert_lightgbm(scope, operator, container)\n",
        "\n",
        "def convert_to_onnx(X, model):\n",
        "\n",
        "    update_registered_converter(\n",
        "        LGBMRegressor, 'LightGbmLGBMRegressor',\n",
        "        calculate_linear_regressor_output_shapes,\n",
        "        skl2onnx_convert_lightgbm,\n",
        "        options={'split': None})\n",
        "    \n",
        "    inputs = []\n",
        "    for k, v in zip(X.columns, X.dtypes):\n",
        "        if v == 'int64':\n",
        "            t = Int64TensorType([None, 1])\n",
        "        elif v == 'float64':\n",
        "            t = FloatTensorType([None, 1])\n",
        "        else:\n",
        "            t = StringTensorType([None, 1])\n",
        "        inputs.append((k, t))\n",
        "\n",
        "    output = [('target',FloatTensorType([None, 1]))]\n",
        "\n",
        "    model_onnx = to_onnx(model, initial_types=inputs,final_types=output,\n",
        "                        target_opset={'': 13, 'ai.onnx.ml': 2})\n",
        "\n",
        "\n",
        "    return model_onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prod_moy</th>\n",
              "      <th>DEBIT_VAPEUR_SECH</th>\n",
              "      <th>Grammage</th>\n",
              "      <th>Temp_Ext</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2024-02-05 18:08:00</th>\n",
              "      <td>41.010971</td>\n",
              "      <td>56.825127</td>\n",
              "      <td>81.890221</td>\n",
              "      <td>7.973333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-02-05 18:09:00</th>\n",
              "      <td>40.945065</td>\n",
              "      <td>57.151169</td>\n",
              "      <td>81.766258</td>\n",
              "      <td>7.970000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-02-05 18:10:00</th>\n",
              "      <td>40.980160</td>\n",
              "      <td>56.611277</td>\n",
              "      <td>81.784515</td>\n",
              "      <td>7.966667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-02-05 18:11:00</th>\n",
              "      <td>41.364578</td>\n",
              "      <td>57.379623</td>\n",
              "      <td>82.530579</td>\n",
              "      <td>7.963333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-02-05 18:12:00</th>\n",
              "      <td>41.019264</td>\n",
              "      <td>58.561216</td>\n",
              "      <td>81.824287</td>\n",
              "      <td>7.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-11 04:56:00</th>\n",
              "      <td>37.699162</td>\n",
              "      <td>53.619308</td>\n",
              "      <td>84.705276</td>\n",
              "      <td>5.306667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-11 04:57:00</th>\n",
              "      <td>37.889694</td>\n",
              "      <td>53.735004</td>\n",
              "      <td>85.124123</td>\n",
              "      <td>5.305000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-11 04:58:00</th>\n",
              "      <td>37.784264</td>\n",
              "      <td>54.478428</td>\n",
              "      <td>84.951111</td>\n",
              "      <td>5.303333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-11 04:59:00</th>\n",
              "      <td>37.777130</td>\n",
              "      <td>54.844524</td>\n",
              "      <td>84.920113</td>\n",
              "      <td>5.301667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-11 05:00:00</th>\n",
              "      <td>37.769997</td>\n",
              "      <td>54.816757</td>\n",
              "      <td>84.918045</td>\n",
              "      <td>5.300000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>49613 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Prod_moy  DEBIT_VAPEUR_SECH   Grammage  Temp_Ext\n",
              "Date                                                                  \n",
              "2024-02-05 18:08:00  41.010971          56.825127  81.890221  7.973333\n",
              "2024-02-05 18:09:00  40.945065          57.151169  81.766258  7.970000\n",
              "2024-02-05 18:10:00  40.980160          56.611277  81.784515  7.966667\n",
              "2024-02-05 18:11:00  41.364578          57.379623  82.530579  7.963333\n",
              "2024-02-05 18:12:00  41.019264          58.561216  81.824287  7.960000\n",
              "...                        ...                ...        ...       ...\n",
              "2024-03-11 04:56:00  37.699162          53.619308  84.705276  5.306667\n",
              "2024-03-11 04:57:00  37.889694          53.735004  85.124123  5.305000\n",
              "2024-03-11 04:58:00  37.784264          54.478428  84.951111  5.303333\n",
              "2024-03-11 04:59:00  37.777130          54.844524  84.920113  5.301667\n",
              "2024-03-11 05:00:00  37.769997          54.816757  84.918045  5.300000\n",
              "\n",
              "[49613 rows x 4 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_ref"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# tutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "def sklearn_to_df(data_loader):\n",
        "    X_data = data_loader.data\n",
        "    X_columns = data_loader.feature_names\n",
        "    x = pd.DataFrame(X_data, columns=X_columns)\n",
        "\n",
        "    y_data = data_loader.target\n",
        "    y = pd.Series(y_data, name='target')\n",
        "\n",
        "    return x, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "x, y = sklearn_to_df(fetch_california_housing())\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "#from data_loader import x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "regressor = lgb.LGBMRegressor()\n",
        "regressor.fit(x_train, y_train)\n",
        "regressor_pred = regressor.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "lower = lgb.LGBMRegressor(objective = 'quantile', alpha = 1 - 0.95)\n",
        "lower.fit(x_train, y_train)\n",
        "lower_pred = lower.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "upper = lgb.LGBMRegressor(objective = 'quantile', alpha = 0.95)\n",
        "upper.fit(x_train, y_train)\n",
        "upper_pred = upper.predict(x_test)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.9.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
